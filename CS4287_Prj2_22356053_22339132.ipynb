{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d6e0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[atari] in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: ale-py in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: autorom in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\csbro\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[atari]) (8.6.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium[atari]) (3.1.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium[atari]) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium[atari]) (4.12.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from autorom) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from autorom) (2.32.3)\n",
      "Requirement already satisfied: click in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from autorom) (8.1.8)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\csbro\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.8.0->gymnasium[atari]) (3.21.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\csbro\\appdata\\roaming\\python\\python39\\site-packages (from click->autorom) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->autorom) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->autorom) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->autorom) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\csbro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->autorom) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"gymnasium[atari]\" ale-py autorom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    img = Image.fromarray(frame).convert('L')\n",
    "    img = img.resize((84, 84), Image.NEAREST)\n",
    "    return np.array(img, dtype=np.float32) / 255.0\n",
    "\n",
    "def show_frame_inline(frame_rgb, reward=None, action=None, q_values=None, scale=5, font_size=22):\n",
    "    # copy frame and resize it\n",
    "    arr = frame_rgb\n",
    "    if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "        arr = (np.clip(arr, 0, 1) * 255).astype(np.uint8)\n",
    "    img = Image.fromarray(arr)\n",
    "    img = img.resize((img.width*scale, img.height*scale), Image.NEAREST)\n",
    "\n",
    "    # create context for drawing and font\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    y = 5\n",
    "    spacing = font_size + 4\n",
    "\n",
    "    # draw current reward to gui\n",
    "    if reward is not None:\n",
    "        draw.text((5, y), f\"Reward: {reward:.2f}\", fill=(0,255,0), font=font)\n",
    "        y += spacing\n",
    "\n",
    "    # draw current action to gui\n",
    "    if action is not None:\n",
    "        draw.text((5, y), f\"Action: {action}\", fill=(0,255,0), font=font)\n",
    "        y += spacing\n",
    "\n",
    "    # draw q values to gui\n",
    "    if q_values is not None:\n",
    "        q_str = \", \".join([f\"{v:.2f}\" for v in q_values])\n",
    "        draw.text((5, y), f\"Top Q: {q_str}\", fill=(0,255,0), font=font)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        c, h, w = input_shape # channels, height, width\n",
    "        \n",
    "        # Convolutional feature extractor\n",
    "        # ReLU after each layer ensures nonlinearity.\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(c, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # compute conv out size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, c, h, w)\n",
    "            conv_out_size = int(np.prod(self.conv(dummy).shape[1:]))\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)            # pass input through convolutional feature extractor\n",
    "        x = x.view(x.size(0), -1)   # flatten spacial values into single vector\n",
    "        return self.fc(x)           # pass flattened values through fully connected layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb758b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity, state_shape):\n",
    "        self.capacity = capacity\n",
    "        self.state_shape = state_shape\n",
    "\n",
    "        # initialise empties\n",
    "        self.ptr = 0\n",
    "        self.size = 0\n",
    "        self.states = np.zeros((capacity, *state_shape), dtype=np.float32)\n",
    "        self.next_states = np.zeros((capacity, *state_shape), dtype=np.float32)\n",
    "        self.actions = np.zeros((capacity,), dtype=np.int64)\n",
    "        self.rewards = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.dones = np.zeros((capacity,), dtype=np.float32)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.states[self.ptr] = state\n",
    "        self.next_states[self.ptr] = next_state\n",
    "        self.actions[self.ptr] = action\n",
    "        self.rewards[self.ptr] = reward\n",
    "        self.dones[self.ptr] = float(done)\n",
    "        self.ptr = (self.ptr + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # get random batch from buffer\n",
    "        idx = np.random.choice(self.size, batch_size, replace=False)\n",
    "        return {\n",
    "            \"states\": self.states[idx],\n",
    "            \"actions\": self.actions[idx],\n",
    "            \"rewards\": self.rewards[idx],\n",
    "            \"next_states\": self.next_states[idx],\n",
    "            \"dones\": self.dones[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "def train_step(q_net, target_net, optimizer, batch, gamma=0.99, device=\"cpu\"):\n",
    "    # convert all batch lists to tensors\n",
    "    states = torch.tensor(batch['states'], dtype=torch.float32, device=device)\n",
    "    actions = torch.tensor(batch['actions'], dtype=torch.long, device=device)\n",
    "    rewards = torch.tensor(batch['rewards'], dtype=torch.float32, device=device)\n",
    "    next_states = torch.tensor(batch['next_states'], dtype=torch.float32, device=device)\n",
    "    dones = torch.tensor(batch['dones'], dtype=torch.float32, device=device)\n",
    "\n",
    "    # compute q-values for current states\n",
    "    q_vals = q_net(states)\n",
    "    q_s_a = q_vals.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_q = target_net(next_states)                    # look at the next states\n",
    "        next_q_max = next_q.max(1)[0]                       # find the best next action\n",
    "        target = rewards + gamma * next_q_max * (1 - dones) # build the target value\n",
    "\n",
    "    \n",
    "    # Huber loss between predicted Q(s,a) and target value\n",
    "    loss = F.smooth_l1_loss(q_s_a, target)\n",
    "\n",
    "    # Standard optimizer step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient clipping to avoid exploding updates\n",
    "    torch.nn.utils.clip_grad_norm_(q_net.parameters(), 10.0)\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849d70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Environment\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset(seed=42)\n",
    "\n",
    "# initial lives\n",
    "lives = info.get('lives', 5)\n",
    "\n",
    "# state stack init\n",
    "frame0 = preprocess_frame(obs)\n",
    "state_stack = np.stack([frame0]*4, axis=0)  # shape (4,84,84)\n",
    "state = state_stack.copy()\n",
    "\n",
    "# networks\n",
    "n_actions = env.action_space.n\n",
    "q_net = DQN(input_shape=(4,84,84), n_actions=n_actions).to(device)\n",
    "q_net.train()\n",
    "\n",
    "target_net = DQN(input_shape=(4,84,84), n_actions=n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# replay buffer\n",
    "replay_capacity = 10000\n",
    "buffer = ReplayBuffer(replay_capacity, state_shape=(4,84,84))\n",
    "\n",
    "# hyperparams\n",
    "batch_size = 32                 # size of batches of frames\n",
    "gamma = 0.80                    # how much the aget cares about future rewards\n",
    "initial_eps = 1.0               # initial epsilon before decay\n",
    "final_eps = 0.05                # final epsilon after decay\n",
    "eps_decay_steps = 1_000_00      # linear decay over this many steps\n",
    "start_train = 10000             # number of transitions before training starts\n",
    "train_freq = 4                  # train every n env steps\n",
    "target_update_freq = 10000      # sync target net every n env steps\n",
    "max_env_steps = 1_000_000       # total env steps to run\n",
    "save_path = \"dqn_breakout.pth\"  # path for saved model\n",
    "\n",
    "# rewards & punishments\n",
    "paddle_touch_reward = 0.2\n",
    "alignment_strength = 0.1\n",
    "edge_penalty = 0.1\n",
    "life_lost_penalty = 2.0\n",
    "\n",
    "# bookkeeping\n",
    "total_steps = 0\n",
    "episode = 0\n",
    "loss_history = []\n",
    "prev_paddle_center = None\n",
    "prev_action = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20a0d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\ImageFile.py:554\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    555\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m         qvals \u001b[38;5;241m=\u001b[39m q_net(st)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     98\u001b[0m     top3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(qvals)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 99\u001b[0m     \u001b[43mshow_frame_inline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     last_display \u001b[38;5;241m=\u001b[39m total_steps\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# occasional checkpoint save\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[86], line 29\u001b[0m, in \u001b[0;36mshow_frame_inline\u001b[1;34m(frame_rgb, reward, action, q_values, scale, font_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m     draw\u001b[38;5;241m.\u001b[39mtext((\u001b[38;5;241m5\u001b[39m, y), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Q: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fill\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m), font\u001b[38;5;241m=\u001b[39mfont)\n\u001b[0;32m     28\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\decorator.py:235\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    234\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:729\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    725\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"iPython display hook support for PNG format.\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03m    :returns: PNG version of the image as bytes\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repr_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPNG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:719\u001b[0m, in \u001b[0;36mImage._repr_image\u001b[1;34m(self, image_format, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m b \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(b, image_format, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:2596\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2593\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2596\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\PngImagePlugin.py:1488\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     single_im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[0;32m   1485\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[0;32m   1486\u001b[0m     )\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_im:\n\u001b[1;32m-> 1488\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\ImageFile.py:558\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    556\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 558\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    560\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\csbro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\ImageFile.py:584\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    585\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "display_interval = 5\n",
    "last_display = 0\n",
    "\n",
    "PADDLE_WIDTH = 16\n",
    "PADDLE_Y = 193  \n",
    "\n",
    "while total_steps < max_env_steps:\n",
    "    # epsilon linear decay\n",
    "    eps = max(final_eps, initial_eps - (initial_eps - final_eps) * (total_steps / eps_decay_steps))\n",
    "\n",
    "    # choose action\n",
    "    if random.random() < eps:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            st = torch.tensor(state.astype(np.float32), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            qvals = q_net(st).cpu().numpy()[0]\n",
    "            action = int(np.argmax(qvals))\n",
    "\n",
    "    # step env\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_steps += 1\n",
    "\n",
    "    # multiply base block reward\n",
    "    reward *= 3\n",
    "\n",
    "    # detect life loss and apply penalty\n",
    "    new_lives = info.get('lives', lives)\n",
    "    life_lost = new_lives < lives\n",
    "    lives = new_lives\n",
    "    if life_lost:\n",
    "        reward -= life_lost_penalty\n",
    "\n",
    "    # Check ball close to paddle vertically\n",
    "    # access ram values\n",
    "    ram = env.unwrapped.ale.getRAM()\n",
    "    ball_x = ram[99]\n",
    "    ball_y = ram[101]\n",
    "    paddle_x = ram[72]\n",
    "    paddle_center = paddle_x + 16/2\n",
    "\n",
    "    if abs(ball_y - PADDLE_Y) <= 5:\n",
    "        # Check X overlap with paddle\n",
    "        if paddle_x - 2 <= ball_x <= paddle_x + PADDLE_WIDTH + 2:\n",
    "            reward += paddle_touch_reward\n",
    "    \n",
    "    # Alignemnt reward\n",
    "    if prev_paddle_center is None:\n",
    "        prev_paddle_center = paddle_center\n",
    "    old_dist = abs(prev_paddle_center - ball_x)\n",
    "    new_dist = abs(paddle_center - ball_x)\n",
    "    if new_dist < old_dist:\n",
    "        reward += alignment_strength\n",
    "    prev_paddle_center = paddle_center\n",
    "\n",
    "    # anti edge-hugging\n",
    "    if paddle_center < 10 or paddle_center > 246:  # screen 0â€“255\n",
    "        reward -= edge_penalty\n",
    "\n",
    "    # preprocess next state\n",
    "    next_frame = preprocess_frame(obs)\n",
    "    next_state = np.roll(state, shift=-1, axis=0)\n",
    "    next_state[-1] = next_frame\n",
    "\n",
    "    # training 'done' flag\n",
    "    done_for_training = bool(terminated or truncated)\n",
    "\n",
    "    # push to replay buffer\n",
    "    buffer.push(state.copy(), action, reward, next_state.copy(), done_for_training)\n",
    "\n",
    "    # advance current state\n",
    "    state = next_state\n",
    "\n",
    "    # If the actual episode ended then reset environment and bookkeeping\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "        lives = info.get('lives', 5)\n",
    "        frame0 = preprocess_frame(obs)\n",
    "        state = np.stack([frame0]*4, axis=0)\n",
    "        episode += 1\n",
    "\n",
    "    # Training step\n",
    "    if len(buffer) >= start_train and (total_steps % train_freq == 0):\n",
    "        batch = buffer.sample(batch_size)\n",
    "        loss = train_step(q_net, target_net, optimizer, batch, gamma=gamma, device=device)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    # Update target network periodically\n",
    "    if total_steps % target_update_freq == 0 and total_steps > 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Periodic inline display (less flicker)\n",
    "    if total_steps - last_display >= display_interval:\n",
    "        # compute q-values for overlay\n",
    "        with torch.no_grad():\n",
    "            st = torch.tensor(state.astype(np.float32), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            qvals = q_net(st).cpu().numpy()[0]\n",
    "        top3 = np.sort(qvals)[-3:][::-1]\n",
    "        show_frame_inline(obs, reward=reward, action=action, q_values=top3, scale=4, font_size=18)\n",
    "        last_display = total_steps\n",
    "\n",
    "    # occasional checkpoint save\n",
    "    if total_steps % 50000 == 0 and total_steps > 0:\n",
    "        torch.save({\n",
    "            \"q_net\": q_net.state_dict(),\n",
    "            \"target_net\": target_net.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"total_steps\": total_steps\n",
    "        }, save_path)\n",
    "\n",
    "# end training loop\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42aa7a4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gym.register_envs(ale_py)\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "obs, info = env.reset(seed=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_shape = (4, 84, 84)\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "model = DQN(input_shape, n_actions).to(device)\n",
    "checkpoint = torch.load(\"dqn_breakout.pth\")\n",
    "model.load_state_dict(checkpoint[\"q_net\"])\n",
    "model.eval()\n",
    "\n",
    "frame = preprocess_frame(obs)\n",
    "state = np.stack([frame]*4, axis=0)\n",
    "\n",
    "while True:\n",
    "    # Convert state to tensor\n",
    "    s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    # Greedy action (no randomness)\n",
    "    with torch.no_grad():\n",
    "        q = model(s)\n",
    "        action = int(torch.argmax(q))\n",
    "\n",
    "    # Step environment\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Preprocess new frame\n",
    "    next_frame = preprocess_frame(obs)\n",
    "    next_state = np.roll(state, -1, axis=0)\n",
    "    next_state[-1] = next_frame\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "        frame = preprocess_frame(obs)\n",
    "        state = np.stack([frame]*4, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
